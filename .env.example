# LLM Provider API Keys
# At least one is required for LLM functionality
GOOGLE_API_KEY=your_gemini_key_here
OPENAI_API_KEY=your_openai_key_here

# Default Model Configuration
# Format: "provider:model_name"
# Examples:
#   - gemini:gemini-1.5-flash
#   - gemini:gemini-1.5-pro
#   - openai:gpt-4o-mini
#   - openai:gpt-4o
DEFAULT_MODEL=gemini:gemini-1.5-flash

# LLM Configuration
LLM_MAX_RETRIES=3
LLM_TIMEOUT_SECONDS=60
LLM_BASE_DELAY=1.0
LLM_MAX_DELAY=10.0
LLM_TEMPERATURE=0.0

# CORS Configuration
# Comma-separated list of allowed origins
# Use "*" for development only!
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# Logging Level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO